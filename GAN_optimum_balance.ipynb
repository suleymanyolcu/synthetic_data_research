{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WbCwFJD3nJwE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/dev/null'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"No artists with labels found to put in legend.\") \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import cv2\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow_gan as tfgan\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Dropout, Dense, Reshape, LayerNormalization, LeakyReLU\n",
    "from keras import layers, models\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.metrics.pairwise import polynomial_kernel\n",
    "from scipy.linalg import sqrtm\n",
    "SEED = 36\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "e7uyQfRmWwpT",
    "outputId": "62e370a5-95b6-4c06-b225-cf6db0c87466"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T18:33:06.14457Z",
     "iopub.status.busy": "2023-06-29T18:33:06.144245Z",
     "iopub.status.idle": "2023-06-29T18:33:06.152322Z",
     "shell.execute_reply": "2023-06-29T18:33:06.151511Z",
     "shell.execute_reply.started": "2023-06-29T18:33:06.144546Z"
    },
    "id": "Wdb5eGy6nJwH"
   },
   "outputs": [],
   "source": [
    "class ReadDataset:\n",
    "    def __init__(self, datasetpath, labels, image_shape):\n",
    "        self.datasetpath = datasetpath\n",
    "        self.labels = labels\n",
    "        self.image_shape = image_shape\n",
    "    def returListImages(self,):\n",
    "        self.images = []\n",
    "        for label in self.labels:\n",
    "            self.images.append(list(pathlib.Path(os.path.join(self.datasetpath,\n",
    "                                                              label)).glob('*.*')))\n",
    "    def readImages(self,):\n",
    "        self.returListImages()\n",
    "        self.finalImages = []\n",
    "        labels = []\n",
    "        for label in range(len(self.labels)):\n",
    "            for img in self.images[label]:\n",
    "                img = cv2.imread(str(img), cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img , self.image_shape[:2])\n",
    "                img  = img/255\n",
    "                img = np.expand_dims(img, axis=-1)  # Add channel dimension to get shape (64, 64, 1)\n",
    "                self.finalImages.append(img)\n",
    "                labels.append(label)\n",
    "        images = np.array(self.finalImages)\n",
    "        labels = np.array(labels)\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T19:59:50.168451Z",
     "iopub.status.busy": "2023-06-25T19:59:50.168188Z",
     "iopub.status.idle": "2023-06-25T20:00:38.263631Z",
     "shell.execute_reply": "2023-06-25T20:00:38.262645Z",
     "shell.execute_reply.started": "2023-06-25T19:59:50.168428Z"
    },
    "id": "G0RqasWvnJwI"
   },
   "outputs": [],
   "source": [
    "readDatasetObject = ReadDataset('/tf/chest_xray/train',\n",
    "                               ['NORMAL', 'PNEUMONIA'],\n",
    "                               (64, 64))\n",
    "images, labels = readDatasetObject.readImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-06-25T20:00:38.266081Z",
     "iopub.status.busy": "2023-06-25T20:00:38.265711Z",
     "iopub.status.idle": "2023-06-25T20:00:38.274323Z",
     "shell.execute_reply": "2023-06-25T20:00:38.273417Z",
     "shell.execute_reply.started": "2023-06-25T20:00:38.266049Z"
    },
    "id": "XhfehYH_nJwJ",
    "outputId": "45c1d339-8631-46f6-e974-525c4681e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5216, 64, 64, 1), (5216,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the GAN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T20:00:47.207282Z",
     "iopub.status.busy": "2023-06-25T20:00:47.206974Z",
     "iopub.status.idle": "2023-06-25T20:00:47.242548Z",
     "shell.execute_reply": "2023-06-25T20:00:47.241745Z",
     "shell.execute_reply.started": "2023-06-25T20:00:47.207256Z"
    },
    "id": "hSD9skVjnJwL"
   },
   "outputs": [],
   "source": [
    "class Acgan:\n",
    "    def __init__(self, eta, batch_size, epochs, weight_decay, latent_space,\n",
    "                 image_shape, kernel_size, label_smoothing=0.9):\n",
    "        self.eta = eta\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.weight_decay = weight_decay\n",
    "        self.latent_space = latent_space\n",
    "        self.image_shape = image_shape\n",
    "        self.kernel_size = kernel_size\n",
    "        self.label_smoothing = label_smoothing\n",
    "\n",
    "    def data(self, images, labels):\n",
    "        ytrain = tf.keras.utils.to_categorical(labels)\n",
    "        self.images = images\n",
    "        self.labels = ytrain\n",
    "\n",
    "    def samples(self, G, noize, labels):\n",
    "        images = G.predict([noize, labels])\n",
    "        ys = np.argmax(labels, axis=1)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        for i in range(16):\n",
    "            plt.subplot(2, 8, (i + 1))\n",
    "            plt.imshow(images[i], cmap='gray')\n",
    "            plt.title(ys[i])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def generator(self, inputs, labels):\n",
    "        filters = [256, 128, 64, 32]\n",
    "        padding = 'same'\n",
    "        x = inputs\n",
    "        y = labels\n",
    "        x = layers.concatenate([x, y])\n",
    "        x = layers.Dense(2048)(x)\n",
    "        x = layers.Dense(8*8*filters[0], kernel_regularizer=tf.keras.regularizers.L2(0.001))(x)\n",
    "        x = layers.Reshape((8, 8, filters[0]))(x)\n",
    "        for filter in filters:\n",
    "            if filter >= 64:\n",
    "                strides = 2\n",
    "            else:\n",
    "                strides = 1\n",
    "            x = layers.LayerNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.2)(x)\n",
    "            x = Conv2DTranspose(filter, kernel_size=self.kernel_size, padding=padding, strides=strides)(x)\n",
    "        x = Conv2DTranspose(1, kernel_size=self.kernel_size, padding=padding)(x)\n",
    "        x = layers.Activation('sigmoid')(x)\n",
    "        self.generatorModel = models.Model(inputs=[inputs, labels], outputs=x, name='generator')\n",
    "\n",
    "    def discriminator(self, inputs):\n",
    "        x = inputs\n",
    "        filters = [32, 64, 128, 256]\n",
    "        padding = 'same'\n",
    "        for filter in filters:\n",
    "            if filter < 256:\n",
    "                strides = 2\n",
    "            else:\n",
    "                strides = 1\n",
    "            x = Conv2D(filter, kernel_size=self.kernel_size, padding=padding, strides=strides,\n",
    "                      kernel_regularizer=tf.keras.regularizers.L2(0.001))(x)\n",
    "            x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        outputs = Dense(1)(x)\n",
    "        labelsOutput = Dense(256, kernel_regularizer=tf.keras.regularizers.L2(0.001))(x)\n",
    "        labelsOutput = Dropout(0.3)(labelsOutput)\n",
    "        labelsOutput = Dense(2)(labelsOutput)\n",
    "        labelsOutput = layers.Activation('softmax')(labelsOutput)\n",
    "        self.discriminatorModel = models.Model(inputs=inputs, outputs=[outputs, labelsOutput], name='discriminator')\n",
    "\n",
    "    def build(self):\n",
    "        generatorInput = layers.Input(shape=(self.latent_space))\n",
    "        discriminatorInput = layers.Input(shape=(self.image_shape))\n",
    "        labelsInput = layers.Input(shape=(2,))\n",
    "        self.generator(generatorInput, labelsInput)\n",
    "        self.discriminator(discriminatorInput)\n",
    "        G = self.generatorModel\n",
    "        D = self.discriminatorModel\n",
    "        D.compile(loss=['mse', 'binary_crossentropy'],\n",
    "                 optimizer=tf.keras.optimizers.RMSprop(learning_rate=self.eta, weight_decay=self.weight_decay))\n",
    "        D.summary()\n",
    "        G.summary()\n",
    "        D.trainable = False\n",
    "        GAN = models.Model(inputs=[generatorInput, labelsInput], outputs=D(G([generatorInput, labelsInput])))\n",
    "        GAN.compile(loss=['mse', 'binary_crossentropy'],\n",
    "                   optimizer=tf.keras.optimizers.RMSprop(learning_rate=self.eta*0.5, weight_decay=self.weight_decay*0.5))\n",
    "        GAN.summary()\n",
    "        return G, D, GAN\n",
    "\n",
    "    def save_model_weights(self, G, D, GAN, epoch):\n",
    "        G.save_weights(f'generator_weights_epoch_{epoch}.h5')\n",
    "        D.save_weights(f'discriminator_weights_epoch_{epoch}.h5')\n",
    "        GAN.save_weights(f'gan_weights_epoch_{epoch}.h5')\n",
    "\n",
    "    def load_model_weights(self, G, D, GAN, epoch):\n",
    "        G.load_weights(f'generator_weights_epoch_{epoch}.h5')\n",
    "        D.load_weights(f'discriminator_weights_epoch_{epoch}.h5')\n",
    "        GAN.load_weights(f'gan_weights_epoch_{epoch}.h5')\n",
    "\n",
    "    def trainAlgorithm(self, G, D, GAN):\n",
    "        for epoch in range(self.epochs):\n",
    "            indexs = np.random.randint(0, len(self.images), size=(self.batch_size,))\n",
    "            realImages = self.images[indexs]\n",
    "            realLabels = self.labels[indexs]\n",
    "            realTag = tf.ones(shape=(self.batch_size,))*self.label_smoothing\n",
    "            noize = tf.random.uniform(shape=(self.batch_size, self.latent_space), minval=-1, maxval=1)\n",
    "            fakeLabels = tf.keras.utils.to_categorical(np.random.choice(range(2), size=(self.batch_size)), num_classes=2)\n",
    "            fakeImages = G.predict([noize, fakeLabels], verbose=0)\n",
    "            fakeTag = tf.zeros(shape=(self.batch_size,))\n",
    "            allImages = np.vstack([realImages, fakeImages])\n",
    "            allLabels = np.vstack([realLabels, fakeLabels])\n",
    "            allTags = np.hstack([realTag, fakeTag])\n",
    "            _, dlossTag, dlossLabels = D.train_on_batch(allImages, [allTags, allLabels])\n",
    "            noize = tf.random.uniform(shape=(self.batch_size, self.latent_space), minval=-1, maxval=1)\n",
    "            _, glossTag, glossLabels = GAN.train_on_batch([noize, fakeLabels], [realTag, fakeLabels])\n",
    "            if epoch % 10000 == 0:\n",
    "                print('Epoch: {}'.format(epoch))\n",
    "                print('discriminator loss: [tag: {}, labels: {}], generator loss: [tag: {}, labels: {}]'.format(dlossTag, dlossLabels, glossTag, glossLabels))\n",
    "                self.samples(G, noize, fakeLabels)\n",
    "                # Save model weights\n",
    "                self.save_model_weights(G, D, GAN, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T20:00:47.244305Z",
     "iopub.status.busy": "2023-06-25T20:00:47.243951Z",
     "iopub.status.idle": "2023-06-25T20:00:47.259078Z",
     "shell.execute_reply": "2023-06-25T20:00:47.25812Z",
     "shell.execute_reply.started": "2023-06-25T20:00:47.244274Z"
    },
    "id": "9VzTLEeRnJwM"
   },
   "outputs": [],
   "source": [
    "acgan = Acgan(eta = 0.0002, batch_size = 32, epochs = 0, weight_decay = 6e-9,\n",
    "              latent_space = 100, image_shape = (64, 64, 1), kernel_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T20:00:47.261213Z",
     "iopub.status.busy": "2023-06-25T20:00:47.260791Z",
     "iopub.status.idle": "2023-06-25T20:00:47.273749Z",
     "shell.execute_reply": "2023-06-25T20:00:47.272847Z",
     "shell.execute_reply.started": "2023-06-25T20:00:47.261181Z"
    },
    "id": "d1OqLus_nJwM"
   },
   "outputs": [],
   "source": [
    "acgan.data(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-06-25T20:00:47.276002Z",
     "iopub.status.busy": "2023-06-25T20:00:47.275564Z",
     "iopub.status.idle": "2023-06-25T20:00:50.6587Z",
     "shell.execute_reply": "2023-06-25T20:00:50.65793Z",
     "shell.execute_reply.started": "2023-06-25T20:00:47.27597Z"
    },
    "id": "_sQkxcWunJwN",
    "outputId": "4a96291f-8c85-4a4d-9f58-b08f1c5e1032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 64, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 32, 32, 32)           832       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 32)           0         ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 64)           51264     ['leaky_re_lu_4[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 16, 16, 64)           0         ['conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)            204928    ['leaky_re_lu_5[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 8, 8, 128)            0         ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 256)            819456    ['leaky_re_lu_6[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 8, 8, 256)            0         ['conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 16384)                0         ['leaky_re_lu_7[0][0]']       \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 256)                  4194560   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 256)                  0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 2)                    514       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    16385     ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 2)                    0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5287939 (20.17 MB)\n",
      "Trainable params: 5287939 (20.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 102)                  0         ['input_1[0][0]',             \n",
      "                                                                     'input_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 2048)                 210944    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 16384)                3357081   ['dense[0][0]']               \n",
      "                                                          6                                       \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 8, 8, 256)            0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 8, 8, 256)            512       ['reshape[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)     (None, 8, 8, 256)            0         ['layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 16, 16, 256)          1638656   ['leaky_re_lu[0][0]']         \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 16, 16, 256)          512       ['conv2d_transpose[0][0]']    \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 256)          0         ['layer_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 32, 32, 128)          819328    ['leaky_re_lu_1[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 32, 32, 128)          256       ['conv2d_transpose_1[0][0]']  \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 128)          0         ['layer_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 64, 64, 64)           204864    ['leaky_re_lu_2[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 64, 64, 64)           128       ['conv2d_transpose_2[0][0]']  \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 64, 64, 64)           0         ['layer_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 64, 64, 32)           51232     ['leaky_re_lu_3[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2D  (None, 64, 64, 1)            801       ['conv2d_transpose_3[0][0]']  \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 64, 64, 1)            0         ['conv2d_transpose_4[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36498049 (139.23 MB)\n",
      "Trainable params: 36498049 (139.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " generator (Functional)      (None, 64, 64, 1)            3649804   ['input_1[0][0]',             \n",
      "                                                          9          'input_3[0][0]']             \n",
      "                                                                                                  \n",
      " discriminator (Functional)  [(None, 1),                  5287939   ['generator[0][0]']           \n",
      "                              (None, 2)]                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 41785988 (159.40 MB)\n",
      "Trainable params: 36498049 (139.23 MB)\n",
      "Non-trainable params: 5287939 (20.17 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G, D, GAN = acgan.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = 60000\n",
    "acgan.load_model_weights(G, D, GAN, last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "execution": {
     "iopub.execute_input": "2023-06-25T20:00:51.13774Z",
     "iopub.status.busy": "2023-06-25T20:00:51.137138Z",
     "iopub.status.idle": "2023-06-25T21:29:32.423191Z",
     "shell.execute_reply": "2023-06-25T21:29:32.422153Z",
     "shell.execute_reply.started": "2023-06-25T20:00:51.137706Z"
    },
    "id": "SwjhvCrwnJwP",
    "outputId": "5bed47ac-39be-45ac-de2e-0b8f2dd69cfa",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#acgan.trainAlgorithm(G, D, GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T21:33:15.087639Z",
     "iopub.status.busy": "2023-06-25T21:33:15.087264Z",
     "iopub.status.idle": "2023-06-25T21:33:15.098148Z",
     "shell.execute_reply": "2023-06-25T21:33:15.097174Z",
     "shell.execute_reply.started": "2023-06-25T21:33:15.08761Z"
    },
    "id": "o-j-SeQP9L44"
   },
   "outputs": [],
   "source": [
    "datasetGenerationSize = 5216\n",
    "noize = tf.random.uniform(shape = (datasetGenerationSize, 100), minval = -1, maxval = 1)\n",
    "newlabels = tf.keras.utils.to_categorical(np.random.choice([0, 1], size = (datasetGenerationSize, )), num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-06-25T21:33:25.186051Z",
     "iopub.status.busy": "2023-06-25T21:33:25.18466Z",
     "iopub.status.idle": "2023-06-25T21:33:25.193223Z",
     "shell.execute_reply": "2023-06-25T21:33:25.192157Z",
     "shell.execute_reply.started": "2023-06-25T21:33:25.186011Z"
    },
    "id": "OpMZxDec9L44",
    "outputId": "62f0c6d7-a13c-4019-834e-12ba0f64f7b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([5216, 100]), (5216, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noize.shape, newlabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNWq4Nf5nFzN",
    "outputId": "eb5fefdd-5775-4b68-adad-0851caa51558"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([2532, 2684]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(newlabels, axis = 1), return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-06-25T21:34:07.624409Z",
     "iopub.status.busy": "2023-06-25T21:34:07.623405Z",
     "iopub.status.idle": "2023-06-25T21:34:08.912609Z",
     "shell.execute_reply": "2023-06-25T21:34:08.911656Z",
     "shell.execute_reply.started": "2023-06-25T21:34:07.624366Z"
    },
    "id": "kfcNupOn9L45",
    "outputId": "67f93f93-c4cd-4b0e-9f55-2c376cd18b35",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5216, 64, 64, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagesGeneration = G.predict([noize, newlabels])\n",
    "imagesGeneration.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZOBZ_yIGnk9d",
    "outputId": "15693e62-5f67-414b-df4e-41a8accf01f5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64, 64, 1)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        640       \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 512)               0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 128)               512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14784001 (56.40 MB)\n",
      "Trainable params: 14783681 (56.40 MB)\n",
      "Non-trainable params: 320 (1.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "basemodel = tf.keras.applications.VGG16(weights=None, input_shape=(64, 64, 1),\n",
    "                                        pooling='max', include_top=False)\n",
    "# Model architecture\n",
    "x = layers.Dropout(0.4)(basemodel.output)\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(32)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)  # Assuming binary classification\n",
    "m = tf.keras.models.Model(inputs=basemodel.input, outputs=x)\n",
    "m.compile(loss = 'binary_crossentropy', optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00002))\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5216, 64, 64, 1), (5216,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5216, 64, 64, 1), (5216, 2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagesGeneration.shape, newlabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real data size 2608\n",
      "Synthetic data size 2608\n",
      "Real data size 1304\n",
      "Synthetic data size 3912\n",
      "Real data size 3912\n",
      "Synthetic data size 1304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def combine_data(real_images, real_labels, synthetic_images, synthetic_labels, ratio_real, ratio_synthetic):\n",
    "    \n",
    "    total_real_samples = len(real_images)\n",
    "    total_synthetic_samples = len(synthetic_images)\n",
    "    \n",
    "    real_data_size = int(total_real_samples * (ratio_real / (ratio_real + ratio_synthetic)))\n",
    "    synthetic_data_size = int(total_synthetic_samples * (ratio_synthetic / (ratio_real + ratio_synthetic)))\n",
    "    \n",
    "  \n",
    "    real_data_size = min(real_data_size, total_real_samples)\n",
    "    synthetic_data_size = min(synthetic_data_size, total_synthetic_samples)\n",
    "    \n",
    "    \n",
    "    print(f\"Real data size {real_data_size}\")\n",
    "    print(f\"Synthetic data size {synthetic_data_size}\")\n",
    "    \n",
    "    \n",
    "    real_indices = np.random.choice(total_real_samples, real_data_size, replace=False)\n",
    "    synthetic_indices = np.random.choice(total_synthetic_samples, synthetic_data_size, replace=False)\n",
    "    \n",
    "    combined_images = np.concatenate([real_images[real_indices], synthetic_images[synthetic_indices]], axis=0)\n",
    "    combined_labels = np.concatenate([real_labels[real_indices], synthetic_labels[synthetic_indices]], axis=0)\n",
    "    \n",
    "\n",
    "    combined_images, combined_labels = shuffle(combined_images, combined_labels, random_state=SEED)\n",
    "    \n",
    "    return combined_images, combined_labels\n",
    "\n",
    "combined_images_1_1, combined_labels_1_1 = combine_data(images, labels, imagesGeneration, np.argmax(newlabels, axis=1), 1, 1)\n",
    "combined_images_1_3, combined_labels_1_3 = combine_data(images, labels, imagesGeneration, np.argmax(newlabels, axis=1), 1, 3)\n",
    "combined_images_3_1, combined_labels_3_1 = combine_data(images, labels, imagesGeneration, np.argmax(newlabels, axis=1), 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0wuuo0joZm-",
    "outputId": "0bef0574-d789-4303-821f-1baba1cc1365",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "66/66 [==============================] - 11s 57ms/step - loss: 0.5581 - val_loss: 0.6920\n",
      "Epoch 2/60\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.3072 - val_loss: 0.6883\n",
      "Epoch 3/60\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.2316 - val_loss: 0.6833\n",
      "Epoch 4/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.2237 - val_loss: 0.6534\n",
      "Epoch 5/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.1900 - val_loss: 0.6263\n",
      "Epoch 6/60\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1614 - val_loss: 0.5495\n",
      "Epoch 7/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.1501 - val_loss: 0.4460\n",
      "Epoch 8/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.1400 - val_loss: 0.3996\n",
      "Epoch 9/60\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1423 - val_loss: 0.2461\n",
      "Epoch 10/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.1128 - val_loss: 0.1907\n",
      "Epoch 11/60\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1133 - val_loss: 0.1580\n",
      "Epoch 12/60\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1037 - val_loss: 0.1526\n",
      "Epoch 13/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.1012 - val_loss: 0.1125\n",
      "Epoch 14/60\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.0960 - val_loss: 0.1022\n",
      "Epoch 15/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.0862 - val_loss: 0.0837\n",
      "Epoch 16/60\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0795 - val_loss: 0.0892\n",
      "Epoch 17/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.0752 - val_loss: 0.0830\n",
      "Epoch 18/60\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0787 - val_loss: 0.1321\n",
      "Epoch 19/60\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0874 - val_loss: 0.0979\n",
      "Epoch 20/60\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.0651 - val_loss: 0.0761\n",
      "Epoch 21/60\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0615 - val_loss: 0.0904\n",
      "Epoch 22/60\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0564 - val_loss: 0.0870\n",
      "Epoch 23/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.0564 - val_loss: 0.0686\n",
      "Epoch 24/60\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0546 - val_loss: 0.0868\n",
      "Epoch 25/60\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0540 - val_loss: 0.0759\n",
      "Epoch 26/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.0519 - val_loss: 0.0636\n",
      "Epoch 27/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.0506 - val_loss: 0.0623\n",
      "Epoch 28/60\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0583 - val_loss: 0.0946\n",
      "Epoch 29/60\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0512 - val_loss: 0.0970\n",
      "Epoch 30/60\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.0465 - val_loss: 0.0742\n",
      "Epoch 1/60\n",
      "66/66 [==============================] - 2s 38ms/step - loss: 0.0678 - val_loss: 0.0721\n",
      "Epoch 2/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.0624 - val_loss: 0.0665\n",
      "Epoch 3/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.0526 - val_loss: 0.1072\n",
      "Epoch 4/60\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.0517 - val_loss: 0.0461\n",
      "Epoch 5/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.0440 - val_loss: 0.0427\n",
      "Epoch 6/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.0448 - val_loss: 0.0352\n",
      "Epoch 7/60\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0436 - val_loss: 0.0648\n",
      "Epoch 8/60\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0600 - val_loss: 0.0410\n",
      "Epoch 9/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.0423 - val_loss: 0.0293\n",
      "Epoch 10/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.0360 - val_loss: 0.0917\n",
      "Epoch 11/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.0586 - val_loss: 0.0387\n",
      "Epoch 12/60\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.0421 - val_loss: 0.0306\n",
      "Epoch 1/60\n",
      "66/66 [==============================] - 3s 38ms/step - loss: 0.0888 - val_loss: 0.1390\n",
      "Epoch 2/60\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.0841 - val_loss: 0.0691\n",
      "Epoch 3/60\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0778 - val_loss: 0.0773\n",
      "Epoch 4/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.0630 - val_loss: 0.0606\n",
      "Epoch 5/60\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0559 - val_loss: 0.0615\n",
      "Epoch 6/60\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.0606 - val_loss: 0.0656\n",
      "Epoch 7/60\n",
      "66/66 [==============================] - 3s 38ms/step - loss: 0.0496 - val_loss: 0.0607\n"
     ]
    }
   ],
   "source": [
    "# Train model with 1:1 combined data\n",
    "history_1_1 = m.fit(combined_images_1_1, combined_labels_1_1,\n",
    "                    epochs=60, batch_size=64,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss', mode='min',\n",
    "                                                                restore_best_weights=True)])\n",
    "\n",
    "# Train model with 1:3 combined data\n",
    "history_1_3 = m.fit(combined_images_1_3, combined_labels_1_3,\n",
    "                    epochs=60, batch_size=64,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss', mode='min',\n",
    "                                                                restore_best_weights=True)])\n",
    "\n",
    "# Train model with 3:1 combined data\n",
    "history_3_1 = m.fit(combined_images_3_1, combined_labels_3_1,\n",
    "                    epochs=60, batch_size=64,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss', mode='min', \n",
    "                                                                restore_best_weights=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 2s 9ms/step - loss: 0.0311\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.0268\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.0379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03791326656937599"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(combined_images_1_1, combined_labels_1_1)\n",
    "m.evaluate(combined_images_1_3, combined_labels_1_3)\n",
    "m.evaluate(combined_images_3_1, combined_labels_3_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "def calculate_metrics(model, images, labels):\n",
    "    loss = model.evaluate(images, labels, verbose=0)  \n",
    "    y_pred = tf.squeeze(model.predict(images))\n",
    "    y_pred = y_pred >= 0.5\n",
    "    y_pred = np.array(y_pred, dtype='int32')\n",
    "    labels = np.array(labels, dtype='int32')\n",
    "    acc = accuracy_score(y_pred, labels) * 100\n",
    "    f1 = f1_score(y_pred, labels) * 100\n",
    "    recall = recall_score(y_pred, labels) * 100\n",
    "    precision = precision_score(y_pred, labels) * 100\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1_score': f1,\n",
    "        'recall': recall,\n",
    "        'precision': precision\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 1s 6ms/step\n",
      "1:1 Ratio -> Accuracy: 99.71%, F1 Score: 99.77%, Recall: 99.72%, Precision: 99.82%\n",
      "163/163 [==============================] - 1s 6ms/step\n",
      "1:3 Ratio -> Accuracy: 99.85%, F1 Score: 99.87%, Recall: 99.83%, Precision: 99.90%\n",
      "163/163 [==============================] - 1s 6ms/step\n",
      "3:1 Ratio -> Accuracy: 99.52%, F1 Score: 99.65%, Recall: 99.64%, Precision: 99.66%\n"
     ]
    }
   ],
   "source": [
    "# For 1:1 Ratio\n",
    "metrics_1_1 = calculate_metrics(m, combined_images_1_1, combined_labels_1_1)\n",
    "print(f\"1:1 Ratio -> Accuracy: {metrics_1_1['accuracy']:.2f}%, F1 Score: {metrics_1_1['f1_score']:.2f}%, \"\n",
    "      f\"Recall: {metrics_1_1['recall']:.2f}%, Precision: {metrics_1_1['precision']:.2f}%\")\n",
    "\n",
    "# For 1:3 Ratio\n",
    "metrics_1_3 = calculate_metrics(m, combined_images_1_3, combined_labels_1_3)\n",
    "print(f\"1:3 Ratio -> Accuracy: {metrics_1_3['accuracy']:.2f}%, F1 Score: {metrics_1_3['f1_score']:.2f}%, \"\n",
    "      f\"Recall: {metrics_1_3['recall']:.2f}%, Precision: {metrics_1_3['precision']:.2f}%\")\n",
    "\n",
    "# For 3:1 Ratio\n",
    "metrics_3_1 = calculate_metrics(m, combined_images_3_1, combined_labels_3_1)\n",
    "print(f\"3:1 Ratio -> Accuracy: {metrics_3_1['accuracy']:.2f}%, F1 Score: {metrics_3_1['f1_score']:.2f}%, \"\n",
    "      f\"Recall: {metrics_3_1['recall']:.2f}%, Precision: {metrics_3_1['precision']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
